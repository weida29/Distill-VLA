{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Open-GroundingDino Libero 微调模型可视化验证\n",
        "\n",
        "本notebook用于验证在Libero数据集上微调后的GroundingDINO模型效果。\n",
        "\n",
        "## 功能\n",
        "1. 单张图像检测与可视化\n",
        "2. 批量可视化\n",
        "3. 阈值敏感性分析\n",
        "4. 与Ground Truth对比\n",
        "5. 保存预测结果\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# 设置工作目录\n",
        "SCRIPT_DIR = Path(os.getcwd()).resolve()\n",
        "if str(SCRIPT_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(SCRIPT_DIR))\n",
        "\n",
        "print(f\"Working directory: {SCRIPT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入Open-GroundingDINO相关模块 (使用本地模块，非原版groundingdino)\n",
        "import datasets.transforms as T\n",
        "from util.slconfig import SLConfig\n",
        "from groundingdino.util.utils import clean_state_dict, get_phrases_from_posmap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 配置路径\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 配置路径 - 根据需要修改\n",
        "# ============================================\n",
        "\n",
        "# 项目根目录\n",
        "PROJECT_ROOT = SCRIPT_DIR.parent.parent\n",
        "\n",
        "# 模型配置文件\n",
        "CONFIG_FILE = SCRIPT_DIR / \"config\" / \"cfg_odvg.py\"\n",
        "\n",
        "# 微调后的模型权重路径 (修改为你的实际路径)\n",
        "CHECKPOINT_PATH = PROJECT_ROOT / \"checkpoints\" / \"open_gdino_finetuned\" / \"checkpoint_best_regular.pth\"\n",
        "# 或者使用最新的checkpoint\n",
        "# CHECKPOINT_PATH = PROJECT_ROOT / \"checkpoints\" / \"open_gdino_finetuned\" / \"checkpoint.pth\"\n",
        "\n",
        "# 数据目录\n",
        "DATA_ROOT = PROJECT_ROOT / \"data_processed\" / \"open_gdino_dataset\"\n",
        "IMAGE_ROOT = DATA_ROOT / \"images\"\n",
        "\n",
        "# 验证路径是否存在\n",
        "print(f\"Config file: {CONFIG_FILE} (exists: {CONFIG_FILE.exists()})\")\n",
        "print(f\"Checkpoint: {CHECKPOINT_PATH} (exists: {CHECKPOINT_PATH.exists()})\")\n",
        "print(f\"Image root: {IMAGE_ROOT} (exists: {IMAGE_ROOT.exists()})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 工具函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_image(image_path):\n",
        "    \"\"\"加载并预处理图像\"\"\"\n",
        "    image_pil = Image.open(image_path).convert(\"RGB\")\n",
        "    \n",
        "    transform = T.Compose([\n",
        "        T.RandomResize([800], max_size=1333),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image_tensor, _ = transform(image_pil, None)\n",
        "    return image_pil, image_tensor\n",
        "\n",
        "\n",
        "def load_model(config_path, checkpoint_path, device=\"cuda\"):\n",
        "    \"\"\"加载模型 (仅构建推理所需的模型，跳过criterion和postprocessors)\"\"\"\n",
        "    from models.GroundingDINO.backbone import build_backbone\n",
        "    from models.GroundingDINO.transformer import build_transformer\n",
        "    from models.GroundingDINO.groundingdino import GroundingDINO\n",
        "    \n",
        "    args = SLConfig.fromfile(str(config_path))\n",
        "    args.device = device\n",
        "    \n",
        "    # 直接构建模型（不需要criterion和postprocessors）\n",
        "    backbone = build_backbone(args)\n",
        "    transformer = build_transformer(args)\n",
        "    \n",
        "    model = GroundingDINO(\n",
        "        backbone,\n",
        "        transformer,\n",
        "        num_queries=args.num_queries,\n",
        "        aux_loss=args.aux_loss,\n",
        "        iter_update=True,\n",
        "        query_dim=4,\n",
        "        num_feature_levels=args.num_feature_levels,\n",
        "        nheads=args.nheads,\n",
        "        dec_pred_bbox_embed_share=args.dec_pred_bbox_embed_share,\n",
        "        two_stage_type=args.two_stage_type,\n",
        "        two_stage_bbox_embed_share=args.two_stage_bbox_embed_share,\n",
        "        two_stage_class_embed_share=args.two_stage_class_embed_share,\n",
        "        num_patterns=args.num_patterns,\n",
        "        dn_number=0,\n",
        "        dn_box_noise_scale=args.dn_box_noise_scale,\n",
        "        dn_label_noise_ratio=args.dn_label_noise_ratio,\n",
        "        dn_labelbook_size=args.dn_labelbook_size,\n",
        "        text_encoder_type=args.text_encoder_type,\n",
        "        sub_sentence_present=args.sub_sentence_present,\n",
        "        max_text_len=args.max_text_len,\n",
        "    )\n",
        "    \n",
        "    # weights_only=False for PyTorch 2.6+ compatibility\n",
        "    checkpoint = torch.load(str(checkpoint_path), map_location=\"cpu\", weights_only=False)\n",
        "    \n",
        "    # 处理checkpoint格式\n",
        "    if \"model\" in checkpoint:\n",
        "        state_dict = checkpoint[\"model\"]\n",
        "    else:\n",
        "        state_dict = checkpoint\n",
        "    \n",
        "    load_res = model.load_state_dict(clean_state_dict(state_dict), strict=False)\n",
        "    print(f\"Model loaded: {load_res}\")\n",
        "    \n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_grounding_output(model, image, caption, box_threshold, text_threshold, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    运行模型推理\n",
        "    \n",
        "    Args:\n",
        "        model: GroundingDINO模型\n",
        "        image: 预处理后的图像tensor\n",
        "        caption: 文本提示 (如 \"bowl. plate. drawer.\")\n",
        "        box_threshold: 边界框置信度阈值\n",
        "        text_threshold: 文本匹配阈值\n",
        "        device: 设备\n",
        "    \n",
        "    Returns:\n",
        "        boxes_filt: 过滤后的边界框 [N, 4] (normalized xywh)\n",
        "        pred_phrases: 预测的短语列表\n",
        "        scores: 置信度分数\n",
        "    \"\"\"\n",
        "    caption = caption.lower().strip()\n",
        "    if not caption.endswith(\".\"):\n",
        "        caption = caption + \".\"\n",
        "    \n",
        "    image = image.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(image[None], captions=[caption])\n",
        "    \n",
        "    logits = outputs[\"pred_logits\"].sigmoid()[0]  # (nq, 256)\n",
        "    boxes = outputs[\"pred_boxes\"][0]  # (nq, 4)\n",
        "    \n",
        "    # 过滤低置信度结果\n",
        "    logits_filt = logits.cpu().clone()\n",
        "    boxes_filt = boxes.cpu().clone()\n",
        "    filt_mask = logits_filt.max(dim=1)[0] > box_threshold\n",
        "    logits_filt = logits_filt[filt_mask]\n",
        "    boxes_filt = boxes_filt[filt_mask]\n",
        "    \n",
        "    # 获取预测短语\n",
        "    tokenizer = model.tokenizer\n",
        "    tokenized = tokenizer(caption)\n",
        "    \n",
        "    pred_phrases = []\n",
        "    scores = []\n",
        "    for logit, box in zip(logits_filt, boxes_filt):\n",
        "        pred_phrase = get_phrases_from_posmap(logit > text_threshold, tokenized, tokenizer)\n",
        "        score = logit.max().item()\n",
        "        pred_phrases.append(pred_phrase)\n",
        "        scores.append(score)\n",
        "    \n",
        "    return boxes_filt, pred_phrases, scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义一组颜色用于可视化\n",
        "COLORS = [\n",
        "    (255, 0, 0),      # Red\n",
        "    (0, 255, 0),      # Green\n",
        "    (0, 0, 255),      # Blue\n",
        "    (255, 255, 0),    # Yellow\n",
        "    (255, 0, 255),    # Magenta\n",
        "    (0, 255, 255),    # Cyan\n",
        "    (255, 128, 0),    # Orange\n",
        "    (128, 0, 255),    # Purple\n",
        "    (0, 128, 255),    # Light Blue\n",
        "    (255, 0, 128),    # Pink\n",
        "]\n",
        "\n",
        "def plot_boxes_to_image(image_pil, boxes, labels, scores=None, show_scores=True):\n",
        "    \"\"\"\n",
        "    在图像上绘制边界框和标签\n",
        "    \n",
        "    Args:\n",
        "        image_pil: PIL图像\n",
        "        boxes: 边界框 [N, 4] (normalized xywh format)\n",
        "        labels: 标签列表\n",
        "        scores: 置信度分数列表 (可选)\n",
        "        show_scores: 是否显示分数\n",
        "    \n",
        "    Returns:\n",
        "        绘制后的PIL图像\n",
        "    \"\"\"\n",
        "    image_draw = image_pil.copy()\n",
        "    draw = ImageDraw.Draw(image_draw)\n",
        "    W, H = image_pil.size\n",
        "    \n",
        "    # 尝试加载字体\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 16)\n",
        "    except:\n",
        "        font = ImageFont.load_default()\n",
        "    \n",
        "    for i, (box, label) in enumerate(zip(boxes, labels)):\n",
        "        # 转换坐标: normalized xywh -> pixel xyxy\n",
        "        cx, cy, w, h = box.tolist()\n",
        "        x0 = int((cx - w/2) * W)\n",
        "        y0 = int((cy - h/2) * H)\n",
        "        x1 = int((cx + w/2) * W)\n",
        "        y1 = int((cy + h/2) * H)\n",
        "        \n",
        "        # 获取颜色\n",
        "        color = COLORS[i % len(COLORS)]\n",
        "        \n",
        "        # 绘制边界框\n",
        "        draw.rectangle([x0, y0, x1, y1], outline=color, width=3)\n",
        "        \n",
        "        # 准备标签文本\n",
        "        if scores is not None and show_scores:\n",
        "            text = f\"{label} ({scores[i]:.2f})\"\n",
        "        else:\n",
        "            text = label\n",
        "        \n",
        "        # 绘制标签背景和文本\n",
        "        if hasattr(font, \"getbbox\"):\n",
        "            bbox = draw.textbbox((x0, y0), text, font=font)\n",
        "        else:\n",
        "            tw, th = draw.textsize(text, font=font)\n",
        "            bbox = (x0, y0 - th, x0 + tw, y0)\n",
        "        \n",
        "        # 调整标签位置到框上方\n",
        "        text_h = bbox[3] - bbox[1]\n",
        "        label_y = max(0, y0 - text_h - 4)\n",
        "        \n",
        "        draw.rectangle([x0, label_y, bbox[2] - bbox[0] + x0 + 4, label_y + text_h + 4], fill=color)\n",
        "        draw.text((x0 + 2, label_y + 2), text, fill=\"white\", font=font)\n",
        "    \n",
        "    return image_draw\n",
        "\n",
        "\n",
        "def visualize_detection(image_path, caption, model, box_threshold=0.3, text_threshold=0.25, \n",
        "                        device=\"cuda\", figsize=(12, 8), show_scores=True):\n",
        "    \"\"\"\n",
        "    完整的检测和可视化流程\n",
        "    \"\"\"\n",
        "    # 加载图像\n",
        "    image_pil, image_tensor = load_image(image_path)\n",
        "    \n",
        "    # 运行推理\n",
        "    boxes, phrases, scores = get_grounding_output(\n",
        "        model, image_tensor, caption, box_threshold, text_threshold, device\n",
        "    )\n",
        "    \n",
        "    # 绘制结果\n",
        "    image_with_boxes = plot_boxes_to_image(image_pil, boxes, phrases, scores, show_scores)\n",
        "    \n",
        "    # 显示\n",
        "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
        "    \n",
        "    axes[0].imshow(image_pil)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis(\"off\")\n",
        "    \n",
        "    axes[1].imshow(image_with_boxes)\n",
        "    axes[1].set_title(f\"Detection Result\\nPrompt: {caption}\")\n",
        "    axes[1].axis(\"off\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 打印检测结果\n",
        "    print(f\"\\nDetected {len(boxes)} objects:\")\n",
        "    for i, (phrase, score) in enumerate(zip(phrases, scores)):\n",
        "        print(f\"  {i+1}. {phrase}: {score:.4f}\")\n",
        "    \n",
        "    return boxes, phrases, scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 加载模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 设置设备\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 加载模型\n",
        "model = load_model(CONFIG_FILE, CHECKPOINT_PATH, device=device)\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 加载数据集并测试\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 从数据集中加载样本\n",
        "train_jsonl = DATA_ROOT / \"train.jsonl\"\n",
        "\n",
        "if train_jsonl.exists():\n",
        "    with open(train_jsonl, 'r') as f:\n",
        "        train_data = [json.loads(line) for line in f if line.strip()]\n",
        "    print(f\"Loaded {len(train_data)} training samples\")\n",
        "    \n",
        "    # 显示一个样本的数据结构\n",
        "    print(f\"\\nSample data structure:\")\n",
        "    print(json.dumps(train_data[0], indent=2, ensure_ascii=False))\n",
        "else:\n",
        "    print(f\"Training data not found at {train_jsonl}\")\n",
        "    train_data = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试随机选择的样本\n",
        "if train_data:\n",
        "    sample = random.choice(train_data)\n",
        "    \n",
        "    # 获取图像路径\n",
        "    image_path = IMAGE_ROOT / sample['filename']\n",
        "    \n",
        "    # 从regions中提取物体名称作为prompt\n",
        "    if 'grounding' in sample and 'regions' in sample['grounding']:\n",
        "        objects = [r['phrase'] for r in sample['grounding']['regions']]\n",
        "        prompt = ' . '.join(objects) + ' .'\n",
        "    else:\n",
        "        prompt = \"object\"\n",
        "    \n",
        "    print(f\"Image: {image_path}\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Ground truth regions: {sample.get('grounding', {}).get('regions', [])}\")\n",
        "    \n",
        "    # 运行检测\n",
        "    if image_path.exists():\n",
        "        boxes, phrases, scores = visualize_detection(\n",
        "            image_path, prompt, model,\n",
        "            box_threshold=0.3,\n",
        "            text_threshold=0.25,\n",
        "            device=device\n",
        "        )\n",
        "    else:\n",
        "        print(f\"Image not found: {image_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 批量可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_batch(samples, model, image_root, num_samples=6, box_threshold=0.3, \n",
        "                    text_threshold=0.25, device=\"cuda\", cols=3):\n",
        "    \"\"\"批量可视化多个样本\"\"\"\n",
        "    # 随机选择样本\n",
        "    selected = random.sample(samples, min(num_samples, len(samples)))\n",
        "    \n",
        "    rows = (len(selected) + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 5*rows))\n",
        "    axes = axes.flatten() if rows > 1 or cols > 1 else [axes]\n",
        "    \n",
        "    for idx, sample in enumerate(selected):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        image_path = Path(image_root) / sample['filename']\n",
        "        \n",
        "        if not image_path.exists():\n",
        "            ax.set_title(f\"Image not found\")\n",
        "            ax.axis('off')\n",
        "            continue\n",
        "        \n",
        "        # 获取prompt\n",
        "        if 'grounding' in sample and 'regions' in sample['grounding']:\n",
        "            objects = [r['phrase'] for r in sample['grounding']['regions']]\n",
        "            prompt = ' . '.join(objects) + ' .'\n",
        "        else:\n",
        "            prompt = \"object\"\n",
        "        \n",
        "        # 加载图像\n",
        "        image_pil, image_tensor = load_image(image_path)\n",
        "        \n",
        "        # 运行推理\n",
        "        boxes, phrases, scores = get_grounding_output(\n",
        "            model, image_tensor, prompt, box_threshold, text_threshold, device\n",
        "        )\n",
        "        \n",
        "        # 绘制结果\n",
        "        image_with_boxes = plot_boxes_to_image(image_pil, boxes, phrases, scores)\n",
        "        \n",
        "        ax.imshow(image_with_boxes)\n",
        "        title = prompt[:40] + \"...\" if len(prompt) > 40 else prompt\n",
        "        ax.set_title(f\"Prompt: {title}\", fontsize=10)\n",
        "        ax.axis('off')\n",
        "    \n",
        "    # 隐藏多余的子图\n",
        "    for idx in range(len(selected), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 批量可视化\n",
        "if train_data:\n",
        "    visualize_batch(\n",
        "        train_data, model, IMAGE_ROOT,\n",
        "        num_samples=6,\n",
        "        box_threshold=0.3,\n",
        "        text_threshold=0.25,\n",
        "        device=device,\n",
        "        cols=3\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 与Ground Truth对比\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_with_gt(sample, model, image_root, box_threshold=0.3, text_threshold=0.25, device=\"cuda\"):\n",
        "    \"\"\"可视化预测结果与Ground Truth的对比\"\"\"\n",
        "    image_path = Path(image_root) / sample['filename']\n",
        "    \n",
        "    if not image_path.exists():\n",
        "        print(f\"Image not found: {image_path}\")\n",
        "        return\n",
        "    \n",
        "    image_pil, image_tensor = load_image(image_path)\n",
        "    W, H = image_pil.size\n",
        "    \n",
        "    # 获取Ground Truth\n",
        "    gt_boxes = []\n",
        "    gt_labels = []\n",
        "    if 'grounding' in sample and 'regions' in sample['grounding']:\n",
        "        for region in sample['grounding']['regions']:\n",
        "            bbox = region['bbox']  # [x1, y1, x2, y2] in pixels\n",
        "            # 转换为normalized xywh\n",
        "            x1, y1, x2, y2 = bbox\n",
        "            cx = (x1 + x2) / 2 / W\n",
        "            cy = (y1 + y2) / 2 / H\n",
        "            w = (x2 - x1) / W\n",
        "            h = (y2 - y1) / H\n",
        "            gt_boxes.append([cx, cy, w, h])\n",
        "            gt_labels.append(region['phrase'])\n",
        "    \n",
        "    gt_boxes = torch.tensor(gt_boxes) if gt_boxes else torch.zeros(0, 4)\n",
        "    \n",
        "    # 获取prompt\n",
        "    prompt = ' . '.join(gt_labels) + ' .' if gt_labels else \"object\"\n",
        "    \n",
        "    # 运行推理\n",
        "    pred_boxes, pred_phrases, pred_scores = get_grounding_output(\n",
        "        model, image_tensor, prompt, box_threshold, text_threshold, device\n",
        "    )\n",
        "    \n",
        "    # 绘制GT和预测结果\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    \n",
        "    # 原图\n",
        "    axes[0].imshow(image_pil)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Ground Truth\n",
        "    gt_image = plot_boxes_to_image(image_pil, gt_boxes, gt_labels, show_scores=False)\n",
        "    axes[1].imshow(gt_image)\n",
        "    axes[1].set_title(f\"Ground Truth ({len(gt_labels)} objects)\")\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    # 预测结果\n",
        "    pred_image = plot_boxes_to_image(image_pil, pred_boxes, pred_phrases, pred_scores)\n",
        "    axes[2].imshow(pred_image)\n",
        "    axes[2].set_title(f\"Predictions ({len(pred_boxes)} detections)\")\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.suptitle(f\"Prompt: {prompt}\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 打印详细信息\n",
        "    print(f\"\\nGround Truth: {gt_labels}\")\n",
        "    print(f\"Predictions: {list(zip(pred_phrases, [f'{s:.3f}' for s in pred_scores]))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 与GT对比\n",
        "if train_data:\n",
        "    sample = random.choice(train_data)\n",
        "    visualize_with_gt(sample, model, IMAGE_ROOT, box_threshold=0.3, text_threshold=0.25, device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 阈值敏感性分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_thresholds(image_path, prompt, model, device=\"cuda\"):\n",
        "    \"\"\"分析不同阈值对检测结果的影响\"\"\"\n",
        "    box_thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "    text_threshold = 0.25\n",
        "    \n",
        "    image_pil, image_tensor = load_image(image_path)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, len(box_thresholds), figsize=(4*len(box_thresholds), 4))\n",
        "    \n",
        "    for idx, box_thresh in enumerate(box_thresholds):\n",
        "        boxes, phrases, scores = get_grounding_output(\n",
        "            model, image_tensor, prompt, box_thresh, text_threshold, device\n",
        "        )\n",
        "        \n",
        "        image_with_boxes = plot_boxes_to_image(image_pil, boxes, phrases, scores)\n",
        "        \n",
        "        axes[idx].imshow(image_with_boxes)\n",
        "        axes[idx].set_title(f\"Box thresh: {box_thresh}\\n({len(boxes)} detections)\")\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.suptitle(f\"Prompt: {prompt}\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 阈值分析\n",
        "if train_data:\n",
        "    sample = random.choice(train_data)\n",
        "    image_path = IMAGE_ROOT / sample['filename']\n",
        "    \n",
        "    if 'grounding' in sample and 'regions' in sample['grounding']:\n",
        "        objects = [r['phrase'] for r in sample['grounding']['regions']]\n",
        "        prompt = ' . '.join(objects) + ' .'\n",
        "    else:\n",
        "        prompt = \"object\"\n",
        "    \n",
        "    if image_path.exists():\n",
        "        analyze_thresholds(image_path, prompt, model, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 自定义测试\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 自定义测试 - 修改下面的路径和prompt进行测试\n",
        "# ============================================\n",
        "\n",
        "# 方式1: 指定图像路径和自定义prompt\n",
        "# custom_image_path = PROJECT_ROOT / \"path/to/your/image.jpg\"\n",
        "# custom_prompt = \"bowl . plate . drawer .\"\n",
        "\n",
        "# 方式2: 使用训练数据中的图像,但用自定义prompt\n",
        "if train_data:\n",
        "    # 选择一个样本\n",
        "    sample = train_data[0]  # 或者 random.choice(train_data)\n",
        "    custom_image_path = IMAGE_ROOT / sample['filename']\n",
        "    \n",
        "    # 自定义prompt - 可以尝试不同的物体名称\n",
        "    custom_prompt = \"bowl . plate . cup . drawer . table .\"\n",
        "    \n",
        "    print(f\"Testing with custom prompt:\")\n",
        "    print(f\"  Image: {custom_image_path}\")\n",
        "    print(f\"  Prompt: {custom_prompt}\")\n",
        "    \n",
        "    if custom_image_path.exists():\n",
        "        boxes, phrases, scores = visualize_detection(\n",
        "            custom_image_path, custom_prompt, model,\n",
        "            box_threshold=0.25,  # 可以调低阈值看更多检测结果\n",
        "            text_threshold=0.2,\n",
        "            device=device\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 保存预测结果\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_prediction(image_path, prompt, model, output_path, box_threshold=0.3, \n",
        "                    text_threshold=0.25, device=\"cuda\"):\n",
        "    \"\"\"保存预测结果图像\"\"\"\n",
        "    image_pil, image_tensor = load_image(image_path)\n",
        "    boxes, phrases, scores = get_grounding_output(\n",
        "        model, image_tensor, prompt, box_threshold, text_threshold, device\n",
        "    )\n",
        "    \n",
        "    image_with_boxes = plot_boxes_to_image(image_pil, boxes, phrases, scores)\n",
        "    image_with_boxes.save(output_path)\n",
        "    print(f\"Saved to: {output_path}\")\n",
        "    \n",
        "    return boxes, phrases, scores\n",
        "\n",
        "# 保存预测结果示例\n",
        "output_dir = SCRIPT_DIR / \"visualization_outputs\"\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "if train_data:\n",
        "    # 保存多张预测结果\n",
        "    num_to_save = min(5, len(train_data))\n",
        "    for i, sample in enumerate(train_data[:num_to_save]):\n",
        "        image_path = IMAGE_ROOT / sample['filename']\n",
        "        \n",
        "        if 'grounding' in sample and 'regions' in sample['grounding']:\n",
        "            objects = [r['phrase'] for r in sample['grounding']['regions']]\n",
        "            prompt = ' . '.join(objects) + ' .'\n",
        "        else:\n",
        "            prompt = \"object\"\n",
        "        \n",
        "        if image_path.exists():\n",
        "            output_path = output_dir / f\"prediction_{i:03d}.jpg\"\n",
        "            save_prediction(image_path, prompt, model, output_path, device=device)\n",
        "    \n",
        "    print(f\"\\nSaved {num_to_save} predictions to: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 此cell内容已移至前面的\"3. 加载模型\"部分\n",
        "pass\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
