{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prismatic-VLM VQA能力测试\n",
        "\n",
        "本notebook用于测试VLA-Adapter中原始Prismatic-VLM (Qwen2.5-0.5B) 的视觉问答和推理能力。\n",
        "\n",
        "**目标**：\n",
        "1. 建立VLM reasoning能力的基线\n",
        "2. 了解0.5B模型的能力上限\n",
        "3. 为后续\"VLM能力保留\"实验提供对比基准\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 环境准备\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 确保在项目根目录\n",
        "PROJECT_ROOT = Path(os.getcwd())\n",
        "if PROJECT_ROOT.name != \"VLA-Adapter\":\n",
        "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
        "    os.chdir(PROJECT_ROOT)\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "\n",
        "# 检查GPU\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 加载Prismatic-VLM模型\n",
        "\n",
        "**注意**: 首次运行需要从HuggingFace下载模型。\n",
        "\n",
        "模型地址: https://huggingface.co/Stanford-ILIAD/prism-qwen25-extra-dinosiglip-224px-0_5b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 模型配置\n",
        "MODEL_PATH = \"pretrained_models/prism-qwen25-extra-dinosiglip-224px-0_5b\"\n",
        "\n",
        "# 检查模型是否已下载\n",
        "model_dir = PROJECT_ROOT / MODEL_PATH\n",
        "if not model_dir.exists() or not any(model_dir.iterdir()) if model_dir.exists() else True:\n",
        "    print(\"=\"*60)\n",
        "    print(\"模型尚未下载!\")\n",
        "    print(\"请先运行以下命令下载模型:\")\n",
        "    print(\"=\"*60)\n",
        "    print()\n",
        "    print(\"git lfs install\")\n",
        "    print(f\"git clone https://huggingface.co/Stanford-ILIAD/prism-qwen25-extra-dinosiglip-224px-0_5b {MODEL_PATH}\")\n",
        "    print()\n",
        "    print(\"或者使用huggingface_hub (推荐):\")\n",
        "    print()\n",
        "    print(\"from huggingface_hub import snapshot_download\")\n",
        "    print(f'snapshot_download(repo_id=\"Stanford-ILIAD/prism-qwen25-extra-dinosiglip-224px-0_5b\", local_dir=\"{MODEL_PATH}\")')\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(f\"模型目录存在: {model_dir}\")\n",
        "    print(f\"文件列表: {list(model_dir.iterdir())[:10]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 如果需要下载模型，取消注释并运行此cell\n",
        "# from huggingface_hub import snapshot_download\n",
        "# snapshot_download(\n",
        "#     repo_id=\"Stanford-ILIAD/prism-qwen25-extra-dinosiglip-224px-0_5b\", \n",
        "#     local_dir=str(PROJECT_ROOT / MODEL_PATH)\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用prismatic的load函数加载完整VLM\n",
        "from prismatic.models import load\n",
        "\n",
        "print(\"Loading Prismatic-VLM...\")\n",
        "vlm = load(str(PROJECT_ROOT / MODEL_PATH), hf_token=\"\", load_for_training=False)\n",
        "print(\"VLM loaded successfully!\")\n",
        "\n",
        "# 移动到GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vlm = vlm.to(device)\n",
        "vlm.eval()\n",
        "print(f\"Model moved to: {device}\")\n",
        "\n",
        "# 打印模型信息\n",
        "total_params = sum(p.numel() for p in vlm.parameters())\n",
        "print(f\"Total parameters: {total_params / 1e6:.1f}M\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 准备测试图像\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_test_image(source=\"url\"):\n",
        "    \"\"\"加载测试图像\"\"\"\n",
        "    if source == \"url\":\n",
        "        # 使用网络图片 (一个包含食物的简单图片)\n",
        "        img_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/ai2d-demo.png\"\n",
        "        image = Image.open(requests.get(img_url, stream=True).raw).convert(\"RGB\")\n",
        "    elif source == \"libero\":\n",
        "        # 使用项目中的LIBERO数据\n",
        "        libero_img_path = PROJECT_ROOT / \"data_processed\" / \"bbox_visualization\" / \"episode_00004_bbox.jpg\"\n",
        "        if libero_img_path.exists():\n",
        "            image = Image.open(libero_img_path).convert(\"RGB\")\n",
        "        else:\n",
        "            print(f\"LIBERO image not found: {libero_img_path}\")\n",
        "            print(\"Using URL image instead...\")\n",
        "            return load_test_image(\"url\")\n",
        "    else:\n",
        "        # 使用本地文件\n",
        "        image = Image.open(source).convert(\"RGB\")\n",
        "    \n",
        "    return image\n",
        "\n",
        "# 加载测试图像 (可改为 \"libero\" 测试机器人场景，或提供本地路径)\n",
        "test_image = load_test_image(\"url\")\n",
        "\n",
        "# 显示图像\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(test_image)\n",
        "plt.title(f\"Test Image ({test_image.size[0]}x{test_image.size[1]})\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. VQA测试函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_vlm(vlm, image: Image.Image, question: str, max_new_tokens: int = 128) -> str:\n",
        "    \"\"\"\n",
        "    向VLM提问并获取回答\n",
        "    \n",
        "    Args:\n",
        "        vlm: Prismatic VLM模型\n",
        "        image: PIL图像\n",
        "        question: 问题文本 (不需要包含<image>标记，generate方法会自动处理)\n",
        "        max_new_tokens: 最大生成token数\n",
        "    \n",
        "    Returns:\n",
        "        模型的回答文本\n",
        "    \"\"\"\n",
        "    # 使用VLM的generate方法\n",
        "    # Prismatic VLM的generate会自动处理图像和prompt的组合\n",
        "    with torch.inference_mode():\n",
        "        try:\n",
        "            response = vlm.generate(\n",
        "                image,\n",
        "                question,\n",
        "                do_sample=False,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                temperature=1.0\n",
        "            )\n",
        "        except Exception as e:\n",
        "            response = f\"[Error: {e}]\"\n",
        "    \n",
        "    return response\n",
        "\n",
        "print(\"VQA function defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 运行VQA测试\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义测试问题\n",
        "test_questions = [\n",
        "    # 基础识别\n",
        "    \"What do you see in this image?\",\n",
        "    \"Describe the main objects in this image.\",\n",
        "    \n",
        "    # 物体识别\n",
        "    \"What is the main object in the center of the image?\",\n",
        "    \"List all objects you can identify.\",\n",
        "    \n",
        "    # 颜色/属性\n",
        "    \"What colors can you see in this image?\",\n",
        "    \"Describe the colors of the objects.\",\n",
        "    \n",
        "    # 空间关系\n",
        "    \"Describe the spatial layout of objects in this image.\",\n",
        "    \"What is on the left side of the image?\",\n",
        "    \n",
        "    # 计数\n",
        "    \"How many objects are there in this image?\",\n",
        "    \n",
        "    # 简单推理\n",
        "    \"What is this image about?\",\n",
        "    \"What might happen next in this scene?\"\n",
        "]\n",
        "\n",
        "print(f\"Prepared {len(test_questions)} test questions.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 运行测试\n",
        "print(\"=\"*70)\n",
        "print(\"Prismatic-VLM (Qwen2.5-0.5B) VQA Test Results\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "\n",
        "results = []\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"[Q{i}] {question}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    answer = ask_vlm(vlm, test_image, question)\n",
        "    results.append({\"question\": question, \"answer\": answer})\n",
        "    \n",
        "    print(f\"[A{i}] {answer}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"Test completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
